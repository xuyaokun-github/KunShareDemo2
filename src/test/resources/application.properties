# 测试数据库数据源
spring.datasource.testDataSource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.testDataSource.url=jdbc:mysql://localhost:3306/dbunit_test?useUnicode=true&characterEncoding=utf-8
spring.datasource.testDataSource.username=root
spring.datasource.testDataSource.password=12345678
spring.datasource.testDataSource.type=com.alibaba.druid.pool.DruidDataSource

# 连接池的配置信息
# 初始化大小，最小，最大
spring.datasource.testDataSource.initialSize=5
spring.datasource.testDataSource.minIdle=5
spring.datasource.testDataSource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.testDataSource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.testDataSource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.testDataSource.minEvictableIdleTimeMillis=300000
spring.datasource.testDataSource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testDataSource.testWhileIdle=true
spring.datasource.testDataSource.testOnBorrow=false
spring.datasource.testDataSource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.testDataSource.poolPreparedStatements=true
spring.datasource.testDataSource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.testDataSource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.testDataSource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000

#=====================下面配置和main目录下配置保持一致=====================
spring.application.name=kunsharedemo
server.servlet.context-path=/kunsharedemo
#spring.main.allow-bean-definition-overriding=true

spring.profile.active=dev

management.server.port=10001
management.server.servlet.context-path=/${spring.application.name}
#开启所有端点的访问
management.endpoints.web.exposure.include=*

# =============== eureka  =======================
# 集成eureka注册中心
eureka.client.serviceUrl.defaultZone=http://admin:123456@localhost:1001/eureka/
eureka.client.register-with-eureka=false
# 关闭eureka客户端
eureka.client.enabled=false

# =============== zipkin  =======================
spring.zipkin.base-url=http://192.168.3.105:9411
spring.zipkin.kafka.topic=zipkin
# 设置采样比例为100%
spring.sleuth.sampler.probability=1.0

#暂时关闭zipkin
spring.zipkin.enabled=false

# =================== Spring Batch ===================
#是否自动执行定义的Job，默认是true
spring.batch.job.enabled=false

# Spring Cloud Task
# 禁用Spring Cloud Task自动建表
#spring.cloud.task.initialize.enable=false
# task执行完毕后关闭上下文（一般不需要这样的操作）
#spring.cloud.task.closecontext_enabled=true
# 禁用Spring Cloud Task自动配置
#spring.cloud.task.autoconfiguration.enabled=false
#spring.cloud.task.batch.listener.enable=false

# =================== mysql ===================
# 应用主库（quartz专用的数据源）
spring.datasource.quartzDataSource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.quartzDataSource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf-8
spring.datasource.quartzDataSource.username=root
spring.datasource.quartzDataSource.password=e5906dd7a635176c108e4ba850f6bedc
spring.datasource.quartzDataSource.type=com.alibaba.druid.pool.DruidDataSource

# 连接池的配置信息
# 初始化大小，最小，最大
spring.datasource.quartzDataSource.initialSize=50
spring.datasource.quartzDataSource.minIdle=50
spring.datasource.quartzDataSource.maxActive=200
# 配置获取连接等待超时的时间
spring.datasource.quartzDataSource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.quartzDataSource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.quartzDataSource.minEvictableIdleTimeMillis=300000
spring.datasource.quartzDataSource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.quartzDataSource.testWhileIdle=true
spring.datasource.quartzDataSource.testOnBorrow=false
spring.datasource.quartzDataSource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.quartzDataSource.poolPreparedStatements=true
spring.datasource.quartzDataSource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.quartzDataSource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.quartzDataSource.connectionProperties=password=${spring.datasource.quartzDataSource.password};druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
#数据库密码解密回调
spring.datasource.quartzDataSource.passwordCallbackClassName=cn.com.kun.config.mysql.DBPasswordCallback

# redis（单节点模式）
spring.redis.host=127.0.0.1
spring.redis.password=
spring.redis.port=6379

# =================== spring session ===================
#spring.session.store-type=redis
spring.session.store-type=none
# Session 过期时间，单位s（用默认的即可）
#server.session.timeout=600
# Sessions 刷新模式
spring.session.redis.flush-mode=IMMEDIATE
# Namespace for keys used to store sessions.
spring.session.redis.namespace=spring:session:kunsharedemo

# 通过排除自动配置的方式禁用spring session（不推荐）
#spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.session.SessionAutoConfiguration

# 引入jedis
spring.jedis.pool.host=192.168.3.104
spring.jedis.pool.password=
spring.jedis.pool.port=6379
spring.jedis.pool.minIdle=10
spring.jedis.pool.maxIdle = 20
spring.jedis.pool.maxTotal = 500
spring.jedis.pool.numTestsPerEvictionRun = 3
spring.jedis.pool.testOnBorrow = true
spring.jedis.pool.blockWhenExhausted = false
spring.jedis.pool.testOnReturn = false


# =================== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.3.105-------------------:9092
spring.kafka.listener.missing-topics-fatal=false

# =================== kafka provider  ===================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== kafka consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-hello-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true


# =============== redisson  =======================
# 第一种方式
# redis（集群模式）
#spring.redis.host=127.0.0.1
#spring.redis.port=6379
#spring.redis.timeout=300s
#spring.redis.password=123456
#spring.redis.cluster.max-redirects=5000
#spring.redis.cluster.nodes=192.168.3.105:7001,192.168.3.105:7002,192.168.3.105:7003,192.168.3.105:7004,192.168.3.105:7005,192.168.3.105:7006
#spring.redis.lettuce.pool.max-active=200
#spring.redis.lettuce.pool.min-idle=15
#spring.redis.lettuce.pool.max-idle=100

# 第二种方式
#spring.redis.redisson.config=classpath:conf/redisson.yml

# 第三种方式(自定义配置属性)
# 单实例
redisson.url=127.0.0.1:6379
redisson.cluster.urls=192.168.3.105:7001,192.168.3.105:7002,192.168.3.105:7003,192.168.3.105:7004,192.168.3.105:7005,192.168.3.105:7006
redisson.password=#1#2#3#4#5#6

# =============== session and jwt login  =======================
kunsharedemo.login.type=none
#kunsharedemo.login.type=session
#kunsharedemo.login.type=jwt


# =============== shardingsphere  =======================
# shardingsphere全局开关，false表示关闭，注释掉或者true表示开启
spring.shardingsphere.enabled=false
## 定义全局数据源
spring.shardingsphere.datasource.names=ds-0
# 配置数据源 ds-0
spring.shardingsphere.datasource.ds-0.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.ds-0.driverClassName=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.ds-0.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&characterEncoding=utf8&tinyInt1isBit=false&useSSL=false&serverTimezone=GMT
spring.shardingsphere.datasource.ds-0.username=root
spring.shardingsphere.datasource.ds-0.password=12345678
# 分表策略
# 分表分片健
#spring.shardingsphere.sharding.tables.tbl_student.table-strategy.inline.sharding-column=id_card
# 分表算法（自带算法，必须符合Groovy语法）
#spring.shardingsphere.sharding.tables.tbl_student.table-strategy.inline.algorithm-expression=tbl_student_$->{id_card.toLong() % 4}
# 分表分片健
spring.shardingsphere.sharding.tables.tbl_student.table-strategy.standard.sharding-column=id_card
# 自定义分表算法
spring.shardingsphere.sharding.tables.tbl_student.table-strategy.standard.precise-algorithm-class-name=cn.com.kun.apache.shardingsphere.algorithm.MyPreciseShardingAlgorithm
# 自增主键字段
spring.shardingsphere.sharding.tables.tbl_student.key-generator.column=id
# 自增主键ID 生成方案
spring.shardingsphere.sharding.tables.tbl_student.key-generator.type=SNOWFLAKE
# 是否开启 SQL解析日志
spring.shardingsphere.props.sql.show=true

# =================== Freemarker 配置 ===================
spring.freemarker.template-loader-path=classpath:/templates/
spring.freemarker.cache=false
spring.freemarker.charset=UTF-8
spring.freemarker.check-template-location=true
spring.freemarker.content-type=text/html
spring.freemarker.expose-request-attributes=true
spring.freemarker.expose-session-attributes=false
spring.freemarker.request-context-attribute=request
#必须指定路径规则
spring.freemarker.prefix=/
spring.freemarker.suffix=.ftl

# =================== xxl-job 配置 ===================
### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"
xxl.job.admin.addresses=http://127.0.0.1:8061/xxl-job-admin

### xxl-job executor address
xxl.job.executor.appname=xxl-job-executor-kunsharedemo
xxl.job.executor.ip=
xxl.job.executor.port=9999

### xxl-job, access token
xxl.job.accessToken=

### xxl-job log path
xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler
### xxl-job log retention days
xxl.job.executor.logretentiondays=30

# =================== elasticsearch 配置 ===================
#spring.data.elasticsearch.cluster-name=elasticsearch
#spring.data.elasticsearch.cluster-nodes=192.168.3.105:930000
#spring.data.elasticsearch.repositories.enabled=true
# es服务未启动时，设置为false,禁用repositories接口的初始化（避免启动报错）
#spring.data.elasticsearch.repositories.enabled=false
#spring.elasticsearch.rest.uris=http://192.168.3.105:9200
#spring.elasticsearch.rest.username=elastic
#spring.elasticsearch.rest.password=phoenix2019$


# =================== 全局的技术组件开关 ===================
# 加一层自定义的开发，控制是否启用@EnableTask注解
#kunsharedemo.springcloud-task.enabled=false

# 是否开启手动数据源
# 只有多数据源时才需要开启，否则用自动配置的足够了，所以默认禁用
kunsharedemo.maindb.datasource.enabled=false
#kunsharedemo.maindb.datasource.enabled=true

# 自定义开关：控制@EnableRedisHttpSession是否生效
kunsharedemo.redis-session.enabled=false

#是否启用fastjson做全局json转换器
kunsharedemo.fastjson.enabled=false

# 自定义开关：控制Jedis是否生效
kunsharedemo.jedis.enabled=false

kunsharedemo.redisson.enabled=false
#是否开启redisson集群模式
kunsharedemo.redisson.cluster.enabled=false

# Quartz（禁用Quartz）
kunsharedemo.quartz.enabled=false

# xxl-job（禁用）
kunsharedemo.xxl-job.enabled=false

# 排除自动配置
# 禁用redisson自动配置（不相当于不集成redisson）,注释掉表示开启自动配置(右斜杠分隔行)
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration\
  ,org.redisson.spring.starter.RedissonAutoConfiguration\
  ,org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration\
  ,org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration
#  ,com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure
#  ,org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration



# =================== 业务参数 ===================
nbaplay.number=1
nbaplay.level=super star